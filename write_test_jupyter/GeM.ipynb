{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from GeMPooling import GeMPooling\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from d2l import torch as d2l\n",
    "from mapillary_sls.datasets.msls import MSLS\n",
    "from mapillary_sls.datasets.generic_dataset import ImagesFromList\n",
    "from mapillary_sls.utils.utils import configure_transform\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_CITIES = \"zurich,sf\"\n",
    "\n",
    "root_dir = Path('/datasets/msls').absolute()\n",
    "\n",
    "# get transform\n",
    "meta = {'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}\n",
    "transform = configure_transform(image_dim = (480, 640), meta = meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(new=False):\n",
    "    \"\"\"get the resnet50\"\"\"\n",
    "    pretrained_net = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "    \n",
    "    # if the pretrained_net is not good, use the net\n",
    "    if new == False:\n",
    "        net = pretrained_net\n",
    "    else:\n",
    "        \"\"\"net = nn.Sequential(*list(pretrained_net.children())[:-2])\n",
    "        net.add_module(\"gempooling\", GeMPooling(pretrained_net.fc.in_features, output_size=(1, 1)))\n",
    "        net.add_module(\"fc\", pretrained_net.fc)\"\"\"\n",
    "        net_list = list(pretrained_net.children())\n",
    "        # create new net\n",
    "        net = nn.Sequential()\n",
    "        net.base = nn.Sequential(*net_list[:-2])\n",
    "        # use an adaptiveavg-pooling in the GeMpooling,kernel_size=(1, 1)\n",
    "        gem = GeMPooling(net_list[-1].in_features, output_size=(1, 1))\n",
    "        net.back = nn.Sequential(gem, pretrained_net.fc)\n",
    "\n",
    "    return net\n",
    "\n",
    "net = get_net(new=True)\n",
    "# print(net)\n",
    "# num_epochs, lr, device = 20, 0.01, torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(next(net.fc.parameters()).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): GeMPooling(\n",
      "    (avg_pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (1): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(list(net.children())[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(size=(1, 3, 480, 640))\n",
    "y = net(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====> zurich\n",
      "=====> sf\n"
     ]
    }
   ],
   "source": [
    "# positive are defined within a radius of 25 m 阳性定义在25米的半径范围内\n",
    "posDistThr = 25\n",
    "\n",
    "# choose task to test on [im2im, seq2im, im2seq, seq2seq]\n",
    "task = 'seq2seq'\n",
    "\n",
    "# choose sequence length\n",
    "seq_length = 3\n",
    "\n",
    "# choose subtask to test on [all, s2w, w2s, o2n, n2o, d2n, n2d]\n",
    "subtask = 'all'\n",
    "\n",
    "val_dataset = MSLS(root_dir, cities = SAMPLE_CITIES, transform = transform, mode = 'test',\n",
    "                   task = task, seq_length = seq_length, subtask = subtask, posDistThr = posDistThr)\n",
    "\n",
    "opt = {'batch_size': 5}\n",
    "\n",
    "# get images\n",
    "qLoader = DataLoader(ImagesFromList(val_dataset.qImages[val_dataset.qIdx], transform), **opt)\n",
    "dbLoader = DataLoader(ImagesFromList(val_dataset.dbImages, transform), **opt)\n",
    "\n",
    "# get positive index (we allow some more slack: default 25 m)\n",
    "pIdx = val_dataset.pIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 480, 640])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, batch in enumerate(dbLoader):\n",
    "    x, y = batch\n",
    "    print(len(x))\n",
    "    print(y)\n",
    "    break\n",
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((369,), (0,), (369,), (9306,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.qIdx.shape, val_dataset.pIdx.shape, val_dataset.qImages.shape, val_dataset.dbImages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, batch in enumerate(qLoader):\n",
    "    x, y = batch\n",
    "    print(len(x))\n",
    "    print(y)\n",
    "    break\n",
    "type(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_feature(net, Loader, device, im_or_seq='im'):\n",
    "    \"\"\"create the features and indices\"\"\"\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    result = []\n",
    "    idx = []\n",
    "    i=0\n",
    "    with torch.no_grad():\n",
    "        if im_or_seq == 'im':\n",
    "            for i, (x, y) in enumerate(Loader):\n",
    "                x = x.to(device)\n",
    "                y_hat = net(x)\n",
    "                print(y_hat.shape)\n",
    "                result.append(y_hat)\n",
    "                idx.append(y)\n",
    "                if i == 4:\n",
    "                    break\n",
    "                i += 1\n",
    "        elif im_or_seq == 'seq':\n",
    "            # type(x_list)=list, and len(x_list=seq_length)\n",
    "            for x_list, y in Loader:\n",
    "                y_hat_list = torch.zeros((x_list[0].shape[0], net.fc.out_features)).to(device)\n",
    "                seq_length = len(x_list)\n",
    "                for x in x_list:\n",
    "                    # now the shape of x is(batch_size, 3, 224, 224)\n",
    "                    x = x.to(device)\n",
    "                    y_hat = net(x)\n",
    "                    # compute the mean of all images in the seq\n",
    "                    y_hat_list += y_hat\n",
    "                y_hat = y_hat_list / seq_length\n",
    "                result.append(y_hat)\n",
    "                idx.append(y)  \n",
    "                \n",
    "                if i == 4:\n",
    "                    break\n",
    "                i += 1\n",
    "        result = torch.cat(result, dim=0)\n",
    "        idx = torch.cat(idx, dim=0).reshape(-1, 1)\n",
    "    return result, idx\n",
    "\n",
    "q_result, q_idx = predict_feature(net, qLoader, device, task.split(\"2\")[0])\n",
    "db_result, _ = predict_feature(net, dbLoader, device, task.split(\"2\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([25, 1000]), torch.Size([25, 1]), torch.Size([25, 1000]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_result.shape, q_idx.shape, db_result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 20])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# db_result, db_idx = predict_feature(net_trained, dbLoader, device)\n",
    "def query_to_dbIdx(qfeature, dbfeature):\n",
    "    # for L2 norm:\n",
    "    qfeature_normed = qfeature / torch.norm(qfeature, dim=1, keepdim=True)\n",
    "    dbfeature_normed = dbfeature / torch.norm(dbfeature, dim=1, keepdim=True)\n",
    "\n",
    "    # cos<a,b> of two vecter: a·b / (|a|*|b|)  == similarity of two vector\n",
    "    sim = torch.matmul(qfeature_normed, dbfeature_normed.transpose(0, 1))\n",
    "    # get the index of the first 20 maximum in sim\n",
    "\n",
    "    idx = torch.argsort(sim, dim=1, descending=True)[:, :20]\n",
    "    \n",
    "    return idx\n",
    "\n",
    "\n",
    "def find_keys(indices, val_dataset):\n",
    "    address_all = val_dataset.dbImages[indices]\n",
    "    # save the keys of all the queries\n",
    "    keys_all = []\n",
    "    for address_query in address_all:\n",
    "        # save the 5 keys of one query\n",
    "        keys = []\n",
    "        for address in address_query:\n",
    "            # address：array(['/datasets/msls/train_val/zurich/query/images/EOC7T_l63Z4LLTSSY6zkkg.jpg,\n",
    "            # /datasets/msls/train_val/zurich/query/images/AoD5-ZB5YrgyClbR5qmG4g.jpg,\n",
    "            # /datasets/msls/train_val/zurich/query/images/8VwFgahokEl-0uG-0Yoshg.jpg'], dtype='<U215')\n",
    "            # key = address.split(\"/\")[-1].split(\".\")[0]\n",
    "            address_seq = address.split(\",\")\n",
    "            key_seq = [key_1.split(\"/\")[-1].split(\".\")[0] for key_1 in address_seq]\n",
    "            # need a ',' between keys in the same seq\n",
    "            # we add it when save to the .csv\n",
    "            #if len(key_seq) > 1:\n",
    "            #    key_seq = [key + ',' if i < len(key_seq) - 1 else key for i, key in enumerate(key_seq)]\n",
    "                      \n",
    "            keys.append(key_seq)\n",
    "        keys_all.append(keys)\n",
    "            \n",
    "    return keys_all\n",
    "    \n",
    "# q1_idx = torch.arange(0,109, 1)\n",
    "# q1 = torch.randn(size=(109, 5))\n",
    "# db1 = torch.randn(size=(200, 5))\n",
    "q_idx.cpu()\n",
    "db_idx = query_to_dbIdx(q_result, db_result).cpu()\n",
    "db_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['VBhOO_DV9AMtrCBdEg39IA,',\n",
       "   '_qLwDOh1rhtPc7tVsII-wA,',\n",
       "   '-sSqPMpmsbwv9iAjgKb5sQ']],\n",
       " [['_qLwDOh1rhtPc7tVsII-wA,',\n",
       "   '-sSqPMpmsbwv9iAjgKb5sQ,',\n",
       "   '5TUQ193fbsXUHn2RmJyIUQ']],\n",
       " [['-sSqPMpmsbwv9iAjgKb5sQ,',\n",
       "   '5TUQ193fbsXUHn2RmJyIUQ,',\n",
       "   'P_7zNYGjYObsCIpaM7e3Kg']],\n",
       " [['5TUQ193fbsXUHn2RmJyIUQ,',\n",
       "   'P_7zNYGjYObsCIpaM7e3Kg,',\n",
       "   '5G1h6AKQ4boqkcFazUR_Bw']],\n",
       " [['P_7zNYGjYObsCIpaM7e3Kg,',\n",
       "   '5G1h6AKQ4boqkcFazUR_Bw,',\n",
       "   '9sE-UeCra7KgJx6rNkq9xQ']],\n",
       " [['5G1h6AKQ4boqkcFazUR_Bw,',\n",
       "   '9sE-UeCra7KgJx6rNkq9xQ,',\n",
       "   'ynz1bXUulgXoOClYciv6Og']],\n",
       " [['9sE-UeCra7KgJx6rNkq9xQ,',\n",
       "   'ynz1bXUulgXoOClYciv6Og,',\n",
       "   'vnhuNjWARNoORJ1IhnBgLQ']],\n",
       " [['ynz1bXUulgXoOClYciv6Og,',\n",
       "   'vnhuNjWARNoORJ1IhnBgLQ,',\n",
       "   'S7F1HKQ7S6iTmoxTmuuY3g']],\n",
       " [['vnhuNjWARNoORJ1IhnBgLQ,',\n",
       "   'S7F1HKQ7S6iTmoxTmuuY3g,',\n",
       "   'nCmGP3LI96HAP1VfYlE40g']],\n",
       " [['S7F1HKQ7S6iTmoxTmuuY3g,',\n",
       "   'nCmGP3LI96HAP1VfYlE40g,',\n",
       "   'I-CSP3R29tWtcVwhEAKuKw']],\n",
       " [['nCmGP3LI96HAP1VfYlE40g,',\n",
       "   'I-CSP3R29tWtcVwhEAKuKw,',\n",
       "   'rboEQxSjLSidG8DaoxCeGQ']],\n",
       " [['I-CSP3R29tWtcVwhEAKuKw,',\n",
       "   'rboEQxSjLSidG8DaoxCeGQ,',\n",
       "   'MX5bgNUVCPn8h_lkcDFt9g']],\n",
       " [['rboEQxSjLSidG8DaoxCeGQ,',\n",
       "   'MX5bgNUVCPn8h_lkcDFt9g,',\n",
       "   'HCXSj2itiiEzfB4uMVR6sQ']],\n",
       " [['MX5bgNUVCPn8h_lkcDFt9g,',\n",
       "   'HCXSj2itiiEzfB4uMVR6sQ,',\n",
       "   'Jwy837C1DRJQJhqHCUzbxA']],\n",
       " [['HCXSj2itiiEzfB4uMVR6sQ,',\n",
       "   'Jwy837C1DRJQJhqHCUzbxA,',\n",
       "   '8LbkbTxnB25XAikZtURtbQ']],\n",
       " [['Jwy837C1DRJQJhqHCUzbxA,',\n",
       "   '8LbkbTxnB25XAikZtURtbQ,',\n",
       "   'jqp3lJVjfKIlFAlI1ywBkA']],\n",
       " [['8LbkbTxnB25XAikZtURtbQ,',\n",
       "   'jqp3lJVjfKIlFAlI1ywBkA,',\n",
       "   'cHgWC31WHryzCtI5cfKZcA']],\n",
       " [['jqp3lJVjfKIlFAlI1ywBkA,',\n",
       "   'cHgWC31WHryzCtI5cfKZcA,',\n",
       "   'SEXwxc572uJ2VPFEqS4OpA']],\n",
       " [['cHgWC31WHryzCtI5cfKZcA,',\n",
       "   'SEXwxc572uJ2VPFEqS4OpA,',\n",
       "   'S9a8M3uQyLKF5ViLwbZypw']],\n",
       " [['SEXwxc572uJ2VPFEqS4OpA,',\n",
       "   'S9a8M3uQyLKF5ViLwbZypw,',\n",
       "   'C9ClRPK2pRoxNbqtrfwIqw']],\n",
       " [['S9a8M3uQyLKF5ViLwbZypw,',\n",
       "   'C9ClRPK2pRoxNbqtrfwIqw,',\n",
       "   '2CqwLRUklnIl4-glqNEK7w']],\n",
       " [['2LkzlTQwJUt3wdRLkrNIUw,',\n",
       "   'zFFI6mh915XNrMfpfh8m5A,',\n",
       "   'JAMcVDMgBWtaU6QQcYviAQ']],\n",
       " [['zFFI6mh915XNrMfpfh8m5A,',\n",
       "   'JAMcVDMgBWtaU6QQcYviAQ,',\n",
       "   'DMXGNMFJf-RalFfJqqc0Jw']],\n",
       " [['JAMcVDMgBWtaU6QQcYviAQ,',\n",
       "   'DMXGNMFJf-RalFfJqqc0Jw,',\n",
       "   'vE5Kq5KbRCuQhT3L8yjQ4g']],\n",
       " [['DMXGNMFJf-RalFfJqqc0Jw,',\n",
       "   'vE5Kq5KbRCuQhT3L8yjQ4g,',\n",
       "   'gDdRQCsidiKgZtr22ApFDA']]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "q_keys = find_keys(q_idx, val_dataset)\n",
    "q_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/datasets/msls/train_val/zurich/query/images/AoD5-ZB5YrgyClbR5qmG4g.jpg'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address_all = val_dataset.qImages[q_idx]\n",
    "key=address_all[0][0]\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_all = val_dataset.qImages[db_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/datasets/msls/train_val/zurich/query/images/AoD5-ZB5YrgyClbR5qmG4g.jpg']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_3= key.split(\",\")\n",
    "key_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AoD5-ZB5YrgyClbR5qmG4g']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = [key_1.split(\"/\")[-1].split(\".\")[0] for key_1 in key_3]\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_keys = find_keys(db_idx, val_dataset)\n",
    "q_keys = find_keys(q_idx, val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_key_seq(key_col, f):\n",
    "    \"\"\"write one key seq for a image/seq to csv\"\"\"\n",
    "    for i, q_key in enumerate(key_col):\n",
    "        if i > 0:\n",
    "            f.write(',' + str(q_key))\n",
    "        else:\n",
    "            f.write(str(q_key))\n",
    "\n",
    "\n",
    "def save_to_csv(q_keys, db_keys, path):\n",
    "    \"\"\"save the keys in csv, seq_length q_keys match to 20*seq_length db_keys\"\"\"\n",
    "    # create the csv saved keys\n",
    "    os.makedirs(os.path.join('.', 'files'), exist_ok=True)\n",
    "    data_file = path\n",
    "    \n",
    "    with open(data_file, 'w') as f:\n",
    "        # one query key match to 5 database keys\n",
    "        # db_keys size(query_num, 20, seq_length)\n",
    "        # q_keys size(query_num, 1, seq_length)\n",
    "        for db_one, q_one in zip(db_keys, q_keys):\n",
    "            # 20 db col after 1 q_col\n",
    "            for q_col in q_one:\n",
    "                # len(q_col) = seq_length\n",
    "                write_key_seq(q_col, f)\n",
    "                f.write(' ')\n",
    "                for db_col in db_one:\n",
    "                    write_key_seq(db_col, f)\n",
    "                    f.write(' ')\n",
    "            f.write(\"\\n\")\n",
    "path = Path('./results_seq.csv')\n",
    "save_to_csv(q_keys, db_keys, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
